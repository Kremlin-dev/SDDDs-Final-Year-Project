{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kremlin-dev/Driver_Drowsiness-Detection-FinalYearProject/blob/main/drowsy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yuOzd8uymCgc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dropout, Conv2D, Flatten, Dense, MaxPooling2D, BatchNormalization\n",
        "import random, shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True, batch_size=1, target_size=(24, 24), class_mode='categorical'):\n",
        "    return gen.flow_from_directory(dir, batch_size=batch_size, shuffle=shuffle, color_mode='grayscale', class_mode=class_mode, target_size=target_size)"
      ],
      "metadata": {
        "id": "_pE7k1DMRpMt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qCJCrJ1amXjz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7180bb-6c64-437c-f26c-774a50bd0ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1234 images belonging to 2 classes.\n",
            "Found 218 images belonging to 2 classes.\n",
            "38 6\n"
          ]
        }
      ],
      "source": [
        "BS = 32\n",
        "TS = (24, 24)\n",
        "train_batch = generator('/content/drive/MyDrive/ROI/dataset/train', shuffle=True, batch_size=BS, target_size=TS)\n",
        "valid_batch = generator('/content/drive/MyDrive/ROI/dataset/test', shuffle=True, batch_size=BS, target_size=TS)\n",
        "SPE = len(train_batch.classes) // BS\n",
        "VS = len(valid_batch.classes) // BS\n",
        "print(SPE, VS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UT8VNw5DmcEl"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(24, 24, 1)),\n",
        "    MaxPooling2D(pool_size=(1, 1)),\n",
        "    Conv2D(16, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(1, 1)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(1, 1)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NXZJT2ZbUha7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_batch, validation_data=valid_batch, epochs=15, steps_per_epoch=SPE, validation_steps=VS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuCpUMZbUk2W",
        "outputId": "c39ba38c-0bdf-4e7a-d8d2-89f0c6f168d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "38/38 [==============================] - 14s 293ms/step - loss: 0.4734 - accuracy: 0.7679 - val_loss: 0.2674 - val_accuracy: 0.8958\n",
            "Epoch 2/15\n",
            "38/38 [==============================] - 10s 254ms/step - loss: 0.2877 - accuracy: 0.9085 - val_loss: 0.1575 - val_accuracy: 0.9323\n",
            "Epoch 3/15\n",
            "38/38 [==============================] - 9s 226ms/step - loss: 0.1904 - accuracy: 0.9376 - val_loss: 0.1472 - val_accuracy: 0.9375\n",
            "Epoch 4/15\n",
            "38/38 [==============================] - 10s 253ms/step - loss: 0.1445 - accuracy: 0.9559 - val_loss: 0.1431 - val_accuracy: 0.9375\n",
            "Epoch 5/15\n",
            "38/38 [==============================] - 11s 298ms/step - loss: 0.1294 - accuracy: 0.9584 - val_loss: 0.1272 - val_accuracy: 0.9323\n",
            "Epoch 6/15\n",
            "38/38 [==============================] - 9s 248ms/step - loss: 0.1016 - accuracy: 0.9667 - val_loss: 0.1147 - val_accuracy: 0.9531\n",
            "Epoch 7/15\n",
            "38/38 [==============================] - 9s 239ms/step - loss: 0.0841 - accuracy: 0.9667 - val_loss: 0.2975 - val_accuracy: 0.9062\n",
            "Epoch 8/15\n",
            "38/38 [==============================] - 8s 217ms/step - loss: 0.1058 - accuracy: 0.9684 - val_loss: 0.1363 - val_accuracy: 0.9531\n",
            "Epoch 9/15\n",
            "38/38 [==============================] - 10s 260ms/step - loss: 0.0673 - accuracy: 0.9759 - val_loss: 0.1271 - val_accuracy: 0.9583\n",
            "Epoch 10/15\n",
            "38/38 [==============================] - 10s 268ms/step - loss: 0.0420 - accuracy: 0.9850 - val_loss: 0.1073 - val_accuracy: 0.9635\n",
            "Epoch 11/15\n",
            "38/38 [==============================] - 9s 226ms/step - loss: 0.0361 - accuracy: 0.9850 - val_loss: 0.1321 - val_accuracy: 0.9479\n",
            "Epoch 12/15\n",
            "38/38 [==============================] - 10s 254ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.1819 - val_accuracy: 0.9583\n",
            "Epoch 13/15\n",
            "38/38 [==============================] - 10s 277ms/step - loss: 0.0315 - accuracy: 0.9884 - val_loss: 0.1146 - val_accuracy: 0.9583\n",
            "Epoch 14/15\n",
            "38/38 [==============================] - 8s 219ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.1144 - val_accuracy: 0.9635\n",
            "Epoch 15/15\n",
            "38/38 [==============================] - 10s 251ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.1067 - val_accuracy: 0.9635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f70b01126e0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, '/content/drive/MyDrive/ROI/saved_model')"
      ],
      "metadata": {
        "id": "LGp15k65jybv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/ROI/drowsinessv3.h5', overwrite=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmYrTHolj2TA",
        "outputId": "ec03440b-e3c6-4c85-fc63-4609f1cfe142"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_representative_data():\n",
        "    # Load your dataset here\n",
        "    # Example: loading images from a directory\n",
        "    import os\n",
        "    from tensorflow.keras.preprocessing import image\n",
        "\n",
        "    data_dir = '/content/drive/MyDrive/ROI/dataset/test'\n",
        "    image_paths = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, fname))] # Filter to include only files\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = img_array.astype(np.float32) / 255.0  # Normalize if necessary\n",
        "        yield [img_array]\n",
        "\n",
        "def representative_dataset():\n",
        "    for data in load_representative_data():\n",
        "        yield data"
      ],
      "metadata": {
        "id": "rnX4ZW_Zd2bs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saved_model_dir = '/content/saved_model'\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/ROI/drowsinessv3.h5')"
      ],
      "metadata": {
        "id": "RPOiSCxEd-o5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Set the optimization strategy\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Set the representative dataset\n",
        "converter.representative_dataset = representative_dataset\n",
        "\n",
        "# Ensure full integer quantization for all ops\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "\n",
        "# Convert the model\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "with open('/content/drive/MyDrive/ROI/model_quantized.tflite', 'wb') as f:\n",
        "    f.write(tflite_quant_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1jAQkrdegDO",
        "outputId": "07cb22bb-3b41-4d72-df12-381781ddaf78"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('drowsinessv3.h5', overwrite=True)"
      ],
      "metadata": {
        "id": "mZVZzw_gU1_0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('drowsinessv3.keras')"
      ],
      "metadata": {
        "id": "t7jVbKNVU6pX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, '/content/drive/MyDrive/ROI/saved_model')"
      ],
      "metadata": {
        "id": "B-wfLaL8U9uk"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1luzwi6VFeaVsLhz0pTO7HEP3AAu8t9Oo",
      "authorship_tag": "ABX9TyPSqKEPkudMFZnyrdF5BBST",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}